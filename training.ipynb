{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM85KSxRmoGIGsv1Qqi1Bp3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hchristiaan/ParlAI/blob/master/training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTfzGqTkIpMN",
        "outputId": "40aaa45b-8a7e-49cd-af0f-6eca118c7458",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install folium==0.2.1\n",
        "!pip install requests==2.23.0\n",
        "!pip install pyyaml==5.1\n",
        "!pip install Sphinx==3.0\n",
        "!pip install urllib3==1.25.4\n",
        "!pip install -q parlai\n",
        "!pip install -q subword_nmt # extra requirement we need for this tutorial"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: folium==0.2.1 in /usr/local/lib/python3.6/dist-packages (0.2.1)\n",
            "Requirement already satisfied: Jinja2 in /usr/local/lib/python3.6/dist-packages (from folium==0.2.1) (2.11.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2->folium==0.2.1) (1.1.1)\n",
            "Requirement already satisfied: requests==2.23.0 in /usr/local/lib/python3.6/dist-packages (2.23.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests==2.23.0) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests==2.23.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests==2.23.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests==2.23.0) (3.0.4)\n",
            "Requirement already satisfied: pyyaml==5.1 in /usr/local/lib/python3.6/dist-packages (5.1)\n",
            "Requirement already satisfied: Sphinx==3.0 in /usr/local/lib/python3.6/dist-packages (3.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml in /usr/local/lib/python3.6/dist-packages (from Sphinx==3.0) (1.1.4)\n",
            "Requirement already satisfied: babel>=1.3 in /usr/local/lib/python3.6/dist-packages (from Sphinx==3.0) (2.8.0)\n",
            "Requirement already satisfied: docutils>=0.12 in /usr/local/lib/python3.6/dist-packages (from Sphinx==3.0) (0.15.2)\n",
            "Requirement already satisfied: sphinxcontrib-devhelp in /usr/local/lib/python3.6/dist-packages (from Sphinx==3.0) (1.0.2)\n",
            "Requirement already satisfied: Jinja2>=2.3 in /usr/local/lib/python3.6/dist-packages (from Sphinx==3.0) (2.11.2)\n",
            "Requirement already satisfied: sphinxcontrib-qthelp in /usr/local/lib/python3.6/dist-packages (from Sphinx==3.0) (1.0.3)\n",
            "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.6/dist-packages (from Sphinx==3.0) (2.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from Sphinx==3.0) (20.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from Sphinx==3.0) (50.3.2)\n",
            "Requirement already satisfied: sphinxcontrib-jsmath in /usr/local/lib/python3.6/dist-packages (from Sphinx==3.0) (1.0.1)\n",
            "Requirement already satisfied: sphinxcontrib-htmlhelp in /usr/local/lib/python3.6/dist-packages (from Sphinx==3.0) (1.0.3)\n",
            "Requirement already satisfied: requests>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from Sphinx==3.0) (2.23.0)\n",
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.6/dist-packages (from Sphinx==3.0) (1.2.0)\n",
            "Requirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.6/dist-packages (from Sphinx==3.0) (2.6.1)\n",
            "Requirement already satisfied: sphinxcontrib-applehelp in /usr/local/lib/python3.6/dist-packages (from Sphinx==3.0) (1.0.2)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.6/dist-packages (from Sphinx==3.0) (0.7.12)\n",
            "Requirement already satisfied: pytz>=2015.7 in /usr/local/lib/python3.6/dist-packages (from babel>=1.3->Sphinx==3.0) (2018.9)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.3->Sphinx==3.0) (1.1.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->Sphinx==3.0) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->Sphinx==3.0) (1.15.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.5.0->Sphinx==3.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.5.0->Sphinx==3.0) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.5.0->Sphinx==3.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.5.0->Sphinx==3.0) (2.10)\n",
            "Collecting urllib3==1.25.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/0d/7777358f672a14b7ae0dfcd29f949f409f913e0578190d6bfa68eb55864b/urllib3-1.25.4-py2.py3-none-any.whl (125kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 2.8MB/s \n",
            "\u001b[?25hInstalling collected packages: urllib3\n",
            "  Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "Successfully installed urllib3-1.25.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RALT32sITd0",
        "outputId": "7427f8bd-6047-46d5-d949-be5b39f31ab0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!rm -rf ako90M\n",
        "!mkdir -p ako90M\n",
        "\n",
        "from parlai.scripts.train_model import TrainModel\n",
        "TrainModel.main(\n",
        "    # similar to before\n",
        "    task='blended_skill_talk,wizard_of_wikipedia,convai2:normalized', \n",
        "    model='transformer/generator',\n",
        "    model_file='ako90M/model',\n",
        "    \n",
        "    # initialize with a pretrained model\n",
        "    init_model='zoo:tutorial_transformer_generator/model',\n",
        "    \n",
        "    # arguments we get from the pretrained model.\n",
        "    # Unfortunately, these must be looked up separately for each model.\n",
        "    n_heads=16, n_layers=8, n_positions=512, text_truncate=512,\n",
        "    label_truncate=128, ffn_size=2048, embedding_size=512,\n",
        "    activation='gelu', variant='xlm',\n",
        "    dict_lower=True, dict_tokenizer='bpe',\n",
        "    dict_file='zoo:tutorial_transformer_generator/model.dict',\n",
        "    learn_positional_embeddings=True,\n",
        "    \n",
        "    # some training arguments, specific to this fine-tuning\n",
        "    # use a small learning rate with ADAM optimizer\n",
        "    lr=1e-6, optimizer='adamax',\n",
        "    warmup_updates=100,\n",
        "    # early stopping on perplexity\n",
        "    validation_metric='ppl',\n",
        "    # train at most 10 minutes, and validate every 0.25 epochs\n",
        "    max_train_time=600, validation_every_n_epochs=0.25,\n",
        "    \n",
        "    # depend on your gpu. If you have a V100, this is good\n",
        "    batchsize=10, fp16=True, fp16_impl='mem_efficient',\n",
        "    \n",
        "    # speeds up validation\n",
        "    skip_generation=True,\n",
        "    \n",
        "    # helps us cram more examples into our gpu at a time\n",
        "    dynamic_batching='full',\n",
        "\n",
        "    #additional options\n",
        "    dropout=0.1,\n",
        "    validation_patience= 15,\n",
        "    save_after_valid=True,\n",
        "    num_epochs=0.25,\n",
        "    save_every_n_secs=60,\n",
        "    validation_metric_mode='min',\n",
        "\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "21:34:31 | building dictionary first...\n",
            "21:34:31 | No model with opt yet at: ako90M/model(.opt)\n",
            "21:34:31 | \u001b[33myour model is being loaded with opts that do not exist in the model you are initializing the weights with: allow_missing_init_opts: False,download_path: None,loglevel: info,dynamic_batching: full,datapath: /usr/local/lib/python3.6/dist-packages/data,tensorboard_logdir: None,label_type: response,include_knowledge: True,include_checked_sentence: True,include_knowledge_separator: False,chosen_topic_delimiter: \n",
            ",num_topics: 5,n_encoder_layers: -1,n_decoder_layers: -1,model_parallel: False,beam_block_full_context: True,beam_length_penalty: 0.65,topk: 10,topp: 0.9,beam_delay: 30,beam_block_list_filename: None,temperature: 1.0,compute_tokenized_bleu: False,interactive_mode: False,fp16_impl: mem_efficient,force_fp16_tokens: False,adafactor_eps: (1e-30, 0.001),history_reversed: False,history_add_global_end_token: None,special_tok_lst: None,bpe_vocab: None,bpe_merge: None,bpe_add_prefix_space: None,hf_skip_special_tokens: True,max_lr_steps: -1,invsqrt_lr_decay_gamma: -1,parlai_home: /usr/local/lib/python3.6/dist-packages\u001b[0m\n",
            "21:34:31 | \u001b[33myour model is being loaded with opts that differ from the model you are initializing the weights with. Add the following args to your run command to change this: \n",
            "--show-advanced-args False --task internal:new_reddit:presorted --datatype train:stream --numthreads 1 --batchsize 48 --num-epochs 5.0 --max-train-time -1 --validation-every-n-secs 1800.0 --save-every-n-secs -1 --validation-every-n-epochs -1 --validation-max-exs 9920 --short-final-eval True --validation-patience 0 --dict-build-first True --numworkers 4 --pytorch-preprocess False --pytorch-teacher-batch-sort False --batch-sort-cache-type pop --batch-length-range 5 --shuffle False --batch-sort-field text --pytorch-context-length -1 --pytorch-include-labels True --log-every-n-secs 30.0 --distributed-world-size 64 --verbose False --port 61337 --beam-size 8 --beam-min-n-best 3 --beam-min-length 10 --skip-generation False --inference beam --optimizer fused_adam --learningrate 0.0005 --gradient-clip 10.0 --adam-eps 1e-06 --betas 0.9,0.98 --weight-decay 0.01 --lr-scheduler invsqrt --warmup-updates 20000 --gpu 0 --beam-block-ngram 3 --beam-context-block-ngram 3\u001b[0m\n",
            "21:34:31 | loading dictionary from /usr/local/lib/python3.6/dist-packages/data/models/tutorial_transformer_generator/model.dict\n",
            "21:34:31 | num words = 54944\n",
            "21:34:33 | \u001b[33mDEPRECATED: XLM should only be used for backwards compatibility, as it involves a less-stable layernorm operation.\u001b[0m\n",
            "21:34:33 | Total parameters: 87,508,992 (87,508,992 trainable)\n",
            "21:34:33 | Loading existing model params from /usr/local/lib/python3.6/dist-packages/data/models/tutorial_transformer_generator/model\n",
            "21:34:56 | \u001b[33mNot loading optim state since optim class changed.\u001b[0m\n",
            "21:34:56 | Opt:\n",
            "21:34:56 |     activation: gelu\n",
            "21:34:56 |     adafactor_eps: '(1e-30, 0.001)'\n",
            "21:34:56 |     adam_eps: 1e-08\n",
            "21:34:56 |     add_p1_after_newln: False\n",
            "21:34:56 |     aggregate_micro: False\n",
            "21:34:56 |     allow_missing_init_opts: False\n",
            "21:34:56 |     attention_dropout: 0.0\n",
            "21:34:56 |     batchsize: 10\n",
            "21:34:56 |     beam_block_full_context: True\n",
            "21:34:56 |     beam_block_list_filename: None\n",
            "21:34:56 |     beam_block_ngram: -1\n",
            "21:34:56 |     beam_context_block_ngram: -1\n",
            "21:34:56 |     beam_delay: 30\n",
            "21:34:56 |     beam_length_penalty: 0.65\n",
            "21:34:56 |     beam_min_length: 1\n",
            "21:34:56 |     beam_size: 1\n",
            "21:34:56 |     betas: '(0.9, 0.999)'\n",
            "21:34:56 |     bpe_add_prefix_space: None\n",
            "21:34:56 |     bpe_debug: False\n",
            "21:34:56 |     bpe_merge: None\n",
            "21:34:56 |     bpe_vocab: None\n",
            "21:34:56 |     chosen_topic_delimiter: '\\n'\n",
            "21:34:56 |     compute_tokenized_bleu: False\n",
            "21:34:56 |     datapath: /usr/local/lib/python3.6/dist-packages/data\n",
            "21:34:56 |     datatype: train\n",
            "21:34:56 |     delimiter: '\\n'\n",
            "21:34:56 |     dict_class: parlai.core.dict:DictionaryAgent\n",
            "21:34:56 |     dict_endtoken: __end__\n",
            "21:34:56 |     dict_file: /usr/local/lib/python3.6/dist-packages/data/models/tutorial_transformer_generator/model.dict\n",
            "21:34:56 |     dict_include_test: False\n",
            "21:34:56 |     dict_include_valid: False\n",
            "21:34:56 |     dict_initpath: None\n",
            "21:34:56 |     dict_language: english\n",
            "21:34:56 |     dict_loaded: True\n",
            "21:34:56 |     dict_lower: True\n",
            "21:34:56 |     dict_max_ngram_size: -1\n",
            "21:34:56 |     dict_maxexs: -1\n",
            "21:34:56 |     dict_maxtokens: -1\n",
            "21:34:56 |     dict_minfreq: 0\n",
            "21:34:56 |     dict_nulltoken: __null__\n",
            "21:34:56 |     dict_starttoken: __start__\n",
            "21:34:56 |     dict_textfields: text,labels\n",
            "21:34:56 |     dict_tokenizer: bpe\n",
            "21:34:56 |     dict_unktoken: __unk__\n",
            "21:34:56 |     display_examples: False\n",
            "21:34:56 |     download_path: None\n",
            "21:34:56 |     dropout: 0.1\n",
            "21:34:56 |     dynamic_batching: full\n",
            "21:34:56 |     embedding_projection: random\n",
            "21:34:56 |     embedding_size: 512\n",
            "21:34:56 |     embedding_type: random\n",
            "21:34:56 |     embeddings_scale: True\n",
            "21:34:56 |     eval_batchsize: None\n",
            "21:34:56 |     evaltask: None\n",
            "21:34:56 |     ffn_size: 2048\n",
            "21:34:56 |     force_fp16_tokens: False\n",
            "21:34:56 |     fp16: True\n",
            "21:34:56 |     fp16_impl: mem_efficient\n",
            "21:34:56 |     gpu: -1\n",
            "21:34:56 |     gradient_clip: 0.1\n",
            "21:34:56 |     hf_skip_special_tokens: True\n",
            "21:34:56 |     hide_labels: False\n",
            "21:34:56 |     history_add_global_end_token: None\n",
            "21:34:56 |     history_reversed: False\n",
            "21:34:56 |     history_size: -1\n",
            "21:34:56 |     image_cropsize: 224\n",
            "21:34:56 |     image_mode: raw\n",
            "21:34:56 |     image_size: 256\n",
            "21:34:56 |     include_checked_sentence: True\n",
            "21:34:56 |     include_knowledge: True\n",
            "21:34:56 |     include_knowledge_separator: False\n",
            "21:34:56 |     inference: greedy\n",
            "21:34:56 |     init_model: /usr/local/lib/python3.6/dist-packages/data/models/tutorial_transformer_generator/model\n",
            "21:34:56 |     init_opt: None\n",
            "21:34:56 |     interactive_mode: False\n",
            "21:34:56 |     invsqrt_lr_decay_gamma: -1\n",
            "21:34:56 |     label_truncate: 128\n",
            "21:34:56 |     label_type: response\n",
            "21:34:56 |     learn_positional_embeddings: True\n",
            "21:34:56 |     learningrate: 1e-06\n",
            "21:34:56 |     load_from_checkpoint: True\n",
            "21:34:56 |     log_every_n_secs: 10\n",
            "21:34:56 |     loglevel: info\n",
            "21:34:56 |     lr_scheduler: reduceonplateau\n",
            "21:34:56 |     lr_scheduler_decay: 0.5\n",
            "21:34:56 |     lr_scheduler_patience: 3\n",
            "21:34:56 |     max_lr_steps: -1\n",
            "21:34:56 |     max_train_time: 600.0\n",
            "21:34:56 |     metrics: default\n",
            "21:34:56 |     model: transformer/generator\n",
            "21:34:56 |     model_file: ako90M/model\n",
            "21:34:56 |     model_parallel: False\n",
            "21:34:56 |     momentum: 0\n",
            "21:34:56 |     multitask_weights: [1]\n",
            "21:34:56 |     n_decoder_layers: -1\n",
            "21:34:56 |     n_encoder_layers: -1\n",
            "21:34:56 |     n_heads: 16\n",
            "21:34:56 |     n_layers: 8\n",
            "21:34:56 |     n_positions: 512\n",
            "21:34:56 |     n_segments: 0\n",
            "21:34:56 |     nesterov: True\n",
            "21:34:56 |     no_cuda: False\n",
            "21:34:56 |     num_epochs: 0.25\n",
            "21:34:56 |     num_topics: 5\n",
            "21:34:56 |     nus: (0.7,)\n",
            "21:34:56 |     optimizer: adamax\n",
            "21:34:56 |     output_scaling: 1.0\n",
            "21:34:56 |     override: \"{'task': 'blended_skill_talk,wizard_of_wikipedia,convai2:normalized', 'model': 'transformer/generator', 'model_file': 'ako90M/model', 'init_model': 'zoo:tutorial_transformer_generator/model', 'n_heads': 16, 'n_layers': 8, 'n_positions': 512, 'text_truncate': 512, 'label_truncate': 128, 'ffn_size': 2048, 'embedding_size': 512, 'activation': 'gelu', 'variant': 'xlm', 'dict_lower': True, 'dict_tokenizer': 'bpe', 'dict_file': '/usr/local/lib/python3.6/dist-packages/data/models/tutorial_transformer_generator/model.dict', 'learn_positional_embeddings': True, 'learningrate': 1e-06, 'optimizer': 'adamax', 'warmup_updates': 100, 'validation_metric': 'ppl', 'max_train_time': 600.0, 'validation_every_n_epochs': 0.25, 'batchsize': 10, 'fp16': True, 'fp16_impl': 'mem_efficient', 'skip_generation': True, 'dynamic_batching': 'full', 'dropout': 0.1, 'validation_patience': 15, 'save_after_valid': True, 'num_epochs': 0.25, 'save_every_n_secs': 60.0, 'validation_metric_mode': 'min'}\"\n",
            "21:34:56 |     parlai_home: /usr/local/lib/python3.6/dist-packages\n",
            "21:34:56 |     person_tokens: False\n",
            "21:34:56 |     rank_candidates: False\n",
            "21:34:56 |     relu_dropout: 0.0\n",
            "21:34:56 |     save_after_valid: True\n",
            "21:34:56 |     save_every_n_secs: 60.0\n",
            "21:34:56 |     share_word_embeddings: True\n",
            "21:34:56 |     short_final_eval: False\n",
            "21:34:56 |     skip_generation: True\n",
            "21:34:56 |     special_tok_lst: None\n",
            "21:34:56 |     split_lines: False\n",
            "21:34:56 |     starttime: Oct29_21-34\n",
            "21:34:56 |     task: blended_skill_talk,wizard_of_wikipedia,convai2:normalized\n",
            "21:34:56 |     temperature: 1.0\n",
            "21:34:56 |     tensorboard_log: False\n",
            "21:34:56 |     tensorboard_logdir: None\n",
            "21:34:56 |     text_truncate: 512\n",
            "21:34:56 |     topk: 10\n",
            "21:34:56 |     topp: 0.9\n",
            "21:34:56 |     truncate: -1\n",
            "21:34:56 |     update_freq: 1\n",
            "21:34:56 |     use_reply: label\n",
            "21:34:56 |     validation_cutoff: 1.0\n",
            "21:34:56 |     validation_every_n_epochs: 0.25\n",
            "21:34:56 |     validation_every_n_secs: -1\n",
            "21:34:56 |     validation_max_exs: -1\n",
            "21:34:56 |     validation_metric: ppl\n",
            "21:34:56 |     validation_metric_mode: min\n",
            "21:34:56 |     validation_patience: 15\n",
            "21:34:56 |     validation_share_agent: False\n",
            "21:34:56 |     variant: xlm\n",
            "21:34:56 |     warmup_rate: 0.0001\n",
            "21:34:56 |     warmup_updates: 100\n",
            "21:34:56 |     weight_decay: None\n",
            "21:34:57 | creating task(s): blended_skill_talk,wizard_of_wikipedia,convai2:normalized\n",
            "21:34:57 | Loading ParlAI text data: /usr/local/lib/python3.6/dist-packages/data/blended_skill_talk/train.txt\n",
            "loading: /usr/local/lib/python3.6/dist-packages/data/wizard_of_wikipedia/train.json\n",
            "21:35:29 | loading normalized fbdialog data: /usr/local/lib/python3.6/dist-packages/data/ConvAI2/train_self_original.txt\n",
            "21:35:29 | loading fbdialog data: /usr/local/lib/python3.6/dist-packages/data/ConvAI2/train_self_original.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Klu97yMrINYz"
      },
      "source": [
        "from parlai.scripts.display_model import DisplayModel\n",
        "DisplayModel.main(\n",
        "    task='blended_skill_talk,wizard_of_wikipedia,convai2:normalized',\n",
        "    model_file='ako90M/model',\n",
        "    num_examples=2,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}